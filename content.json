{
  "hero": {
    "title": "Lakehouse de Cr√©ditos SIMBAD + Macro en GCP",
    "subtitle": "Ingesta ‚Üí Transformaci√≥n ‚Üí M√©tricas. Arquitectura h√≠brida costo-eficiente para an√°lisis de riesgo crediticio en Rep√∫blica Dominicana.",
    "primaryCTA": {"label": "Ver Arquitectura", "href": "#arquitectura"},
    "secondaryCTA": {"label": "Ver Inventario", "href": "#inventario"},
    "badges": ["üèõÔ∏è SIMBAD", "üìä BigQuery", "‚ö° DataProc", "üîÑ Automatizado"]
  },
  "objective": {
    "title": "Objetivo del Proyecto",
    "problem": "Centralizar datos de cr√©ditos hipotecarios SIMBAD e indicadores macroecon√≥micos con baja latencia para an√°lisis de riesgo crediticio.",
    "solution": "Pipeline por capas (Landing ‚Üí Bronze ‚Üí Silver ‚Üí Gold) con ingesta serverless y procesamiento h√≠brido BigQuery/DataProc.",
    "impact": "Menor tiempo a insight, control de costos por uso y automatizaci√≥n completa del pipeline de datos.",
    "benefits": [
      "An√°lisis de riesgo crediticio en tiempo real",
      "Integraci√≥n de datos macroecon√≥micos para contexto",
      "Pipeline automatizado con m√≠nima intervenci√≥n manual",
      "Escalabilidad y eficiencia de costos"
    ]
  },
  "architecture": {
    "title": "Arquitectura H√≠brida",
    "subtitle": "Pipeline completo con DataProc para carga hist√≥rica y BigQuery para procesamiento incremental",
    "layers": [
      {
        "name": "Landing Layer",
        "description": "Ingesta de datos raw desde APIs y fuentes externas",
        "services": ["Cloud Storage", "Cloud Run", "Scheduler"],
        "color": "blue"
      },
      {
        "name": "Bronze Layer", 
        "description": "Almacenamiento de datos en formato original con particionado",
        "services": ["DataProc", "External Tables"],
        "color": "amber"
      },
      {
        "name": "Silver Layer",
        "description": "Datos limpios y normalizados para an√°lisis",
        "services": ["BigQuery", "Stored Procedures"],
        "color": "emerald"
      },
      {
        "name": "Gold Layer",
        "description": "M√©tricas de negocio y agregaciones para dashboards",
        "services": ["M√©tricas", "Alertas", "Visualization"],
        "color": "purple"
      }
    ]
  },
  "inventory": {
    "title": "Servicios Desplegados",
    "subtitle": "Inventario completo de recursos activos en Google Cloud Platform",
    "services": [
      {
        "category": "Compute",
        "items": [
          {"name": "DataProc Cluster", "status": "RUNNING", "specs": "4 workers, cluster-integrador-2025"},
          {"name": "Cloud Run Services", "status": "ACTIVE", "specs": "7 servicios, us-central1"},
          {"name": "Cloud Scheduler", "status": "ACTIVE", "specs": "5:00 AM diario, America/Lima"}
        ]
      },
      {
        "category": "Storage & Data",
        "items": [
          {"name": "Cloud Storage", "status": "ACTIVE", "specs": "dae-integrador-2025, retention 30d"},
          {"name": "BigQuery Datasets", "status": "ACTIVE", "specs": "4 datasets, clustering optimizado"},
          {"name": "External Tables", "status": "ACTIVE", "specs": "Parquet, wildcard detection"}
        ]
      },
      {
        "category": "Processing",
        "items": [
          {"name": "Stored Procedures", "status": "ACTIVE", "specs": "4 procedures con prefijo sp_"},
          {"name": "Jupyter Notebooks", "status": "ACTIVE", "specs": "4 notebooks DataProc"},
          {"name": "Incremental Loaders", "status": "ACTIVE", "specs": "Carga inteligente datos nuevos"}
        ]
      }
    ]
  },
  "tech": {
    "title": "Tecnolog√≠as y Por Qu√©",
    "subtitle": "Justificaci√≥n t√©cnica de las decisiones de arquitectura",
    "technologies": [
      {
        "name": "Google Cloud Platform",
        "reason": "Ecosistema integrado, escalabilidad autom√°tica y costos predecibles",
        "benefits": ["Serverless", "Pay-per-use", "Global infrastructure"]
      },
      {
        "name": "BigQuery",
        "reason": "Data warehouse serverless con procesamiento SQL optimizado",
        "benefits": ["Columnar storage", "Automatic scaling", "Real-time analytics"]
      },
      {
        "name": "DataProc",
        "reason": "Procesamiento distribuido para cargas hist√≥ricas masivas",
        "benefits": ["PySpark", "Auto-scaling", "Cost-effective batch processing"]
      },
      {
        "name": "Cloud Run",
        "reason": "Contenedores serverless para extractores de datos",
        "benefits": ["HTTP triggers", "Auto-scaling", "Zero maintenance"]
      }
    ]
  },
  "costEfficiency": {
    "title": "Eficiencia de Costos",
    "subtitle": "Optimizaci√≥n de recursos y control de gastos",
    "strategies": [
      {
        "strategy": "Serverless Architecture",
        "description": "Pago solo por uso real de recursos",
        "savings": "60-80% vs. instancias siempre activas"
      },
      {
        "strategy": "Incremental Processing", 
        "description": "Procesamiento solo de datos nuevos",
        "savings": "Reducci√≥n de 70% en costos de BigQuery"
      },
      {
        "strategy": "Data Lifecycle Management",
        "description": "Retention policies y particionado inteligente",
        "savings": "50% menos almacenamiento en Cloud Storage"
      },
      {
        "strategy": "Auto-scaling",
        "description": "Escalado autom√°tico seg√∫n demanda",
        "savings": "Eliminaci√≥n de over-provisioning"
      }
    ],
    "monthlyEstimate": "$200-400 USD",
    "breakdown": {
      "BigQuery": "40%",
      "DataProc": "30%", 
      "Cloud Storage": "15%",
      "Cloud Run": "10%",
      "Other": "5%"
    }
  },
  "metrics": {
    "title": "M√©tricas & SLOs",
    "subtitle": "Indicadores de rendimiento y objetivos de nivel de servicio",
    "kpis": [
      {
        "metric": "676K+",
        "label": "Registros SIMBAD",
        "trend": "positive",
        "description": "Datos hist√≥ricos 2012-presente"
      },
      {
        "metric": "4,965",
        "label": "M√©tricas Gold",
        "trend": "positive", 
        "description": "Agregaciones por provincia/per√≠odo"
      },
      {
        "metric": "< 2h",
        "label": "Latencia Pipeline",
        "trend": "positive",
        "description": "Landing ‚Üí Gold end-to-end"
      },
      {
        "metric": "99.9%",
        "label": "Disponibilidad",
        "trend": "positive",
        "description": "Uptime del sistema"
      }
    ],
    "slos": [
      {"service": "Data Ingestion", "target": "99.5%", "current": "99.8%"},
      {"service": "Data Processing", "target": "95%", "current": "97.2%"},
      {"service": "Pipeline Latency", "target": "< 4h", "current": "< 2h"}
    ]
  },
  "team": {
    "title": "Equipo del Proyecto",
    "subtitle": "Integrantes y responsabilidades del proyecto integrador",
    "members": [
      {
        "name": "Ruben Quispe",
        "role": "Data Engineer",
        "focus": "Orquestaci√≥n, BigQuery, DataProc",
        "contributions": [
          "Arquitectura h√≠brida lakehouse",
          "Stored procedures automatizados", 
          "Pipeline CI/CD con Cloud Build",
          "Optimizaci√≥n de costos y performance"
        ]
      },
      {
        "name": "Integrante 2",
        "role": "ML/Analytics Engineer", 
        "focus": "Modelos predictivos y m√©tricas de negocio",
        "contributions": [
          "Desarrollo de m√©tricas de riesgo",
          "Integraci√≥n de datos macroecon√≥micos",
          "Dashboards en Looker Studio",
          "Sistema de alertas autom√°ticas"
        ]
      }
    ]
  },
  "docs": {
    "title": "Documentaci√≥n & Reproducibilidad",
    "subtitle": "Recursos t√©cnicos y gu√≠as de implementaci√≥n",
    "resources": [
      {
        "title": "Documentaci√≥n T√©cnica Interactiva",
        "description": "Vista completa del pipeline con m√©tricas en tiempo real",
        "href": "docs/technical-overview.html",
        "type": "interactive"
      },
      {
        "title": "ARCHITECTURE.md",
        "description": "Documentaci√≥n t√©cnica completa de la arquitectura",
        "href": "ARCHITECTURE.md",
        "type": "markdown"
      },
      {
        "title": "BigQuery Processing",
        "description": "Pipeline SQL con stored procedures automatizados",
        "href": "bigquery_processing/README.md",
        "type": "markdown"
      },
      {
        "title": "DataProc Processing", 
        "description": "Notebooks Jupyter para procesamiento distribuido",
        "href": "lakehouse_processing/README.md",
        "type": "markdown"
      },
      {
        "title": "Repositorio GitHub",
        "description": "C√≥digo completo con historial de commits",
        "href": "https://github.com/noctics123/dmc_proyecto_integrador",
        "type": "external"
      }
    ]
  },
  "faqs": {
    "title": "Preguntas Frecuentes",
    "subtitle": "Respuestas a las consultas m√°s comunes sobre el proyecto",
    "questions": [
      {
        "question": "¬øPor qu√© elegir una arquitectura h√≠brida en lugar de solo BigQuery?",
        "answer": "La arquitectura h√≠brida combina lo mejor de ambos mundos: DataProc para cargas hist√≥ricas masivas (m√°s econ√≥mico) y BigQuery para procesamiento incremental y consultas anal√≠ticas (m√°s r√°pido)."
      },
      {
        "question": "¬øC√≥mo se garantiza la calidad de los datos?",
        "answer": "Implementamos validaciones autom√°ticas, deduplicaci√≥n con ROW_NUMBER(), parsing seguro con SAFE_CAST y flags de calidad en cada capa del pipeline."
      },
      {
        "question": "¬øCu√°l es el costo mensual estimado del proyecto?",
        "answer": "El costo mensual oscila entre $200-400 USD, optimizado con estrategias serverless, procesamiento incremental y lifecycle management de datos."
      },
      {
        "question": "¬øC√≥mo se maneja la escalabilidad del sistema?",
        "answer": "Todos los servicios son auto-escalables: Cloud Run escala a cero, DataProc ajusta workers seg√∫n demanda, y BigQuery escala autom√°ticamente el procesamiento."
      },
      {
        "question": "¬øQu√© pasa si falla alg√∫n componente del pipeline?",
        "answer": "Implementamos exception handling en stored procedures, retry policies en Cloud Run, y monitoreo con alertas autom√°ticas para detecci√≥n temprana de fallos."
      }
    ]
  }
}