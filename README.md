# DMC - Pipeline de Datos Integral

**Sistema completo de anÃ¡lisis de crÃ©ditos hipotecarios SIMBAD e indicadores macroeconÃ³micos usando arquitectura lakehouse hÃ­brida en Google Cloud Platform.**

[![GCP](https://img.shields.io/badge/Google%20Cloud-4285F4?style=flat&logo=google-cloud&logoColor=white)](https://cloud.google.com)
[![BigQuery](https://img.shields.io/badge/BigQuery-4285F4?style=flat&logo=google-cloud&logoColor=white)](https://cloud.google.com/bigquery)
[![DataProc](https://img.shields.io/badge/DataProc-4285F4?style=flat&logo=apache-spark&logoColor=white)](https://cloud.google.com/dataproc)
[![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)](https://python.org)

## ğŸ¯ **VisiÃ³n General**

Pipeline de datos end-to-end que:
- ğŸ“Š **Extrae** datos de SIMBAD (Superintendencia de Bancos RD) y fuentes macroeconÃ³micas
- ğŸ”„ **Procesa** usando arquitectura lakehouse (Landing â†’ Bronze â†’ Silver â†’ Gold)
- ğŸ“ˆ **Genera** mÃ©tricas de riesgo crediticio y KPIs financieros
- âš¡ **Automatiza** con scheduling y triggers inteligentes
- ğŸ“± **Visualiza** en dashboards ejecutivos

## ğŸ—ï¸ **Arquitectura**

```mermaid
graph LR
    A[SIMBAD API] --> B[Landing - CSV]
    C[Macro Data] --> B
    B --> D{Procesamiento}
    D -->|HistÃ³rico| E[DataProc]
    D -->|Incremental| F[BigQuery Direct]
    E --> G[Bronze - Parquet]
    G --> H[Silver - Clean]
    F --> H
    H --> I[Gold - Metrics]
    I --> J[Looker Studio]
```

**Ver documentaciÃ³n completa**: [ARCHITECTURE.md](./ARCHITECTURE.md)

## ğŸ“ **Estructura del Proyecto**

```
â”œâ”€â”€ ğŸ“Š bigquery_processing/           # Pipeline SQL BigQuery
â”‚   â”œâ”€â”€ stored_procedures/           # SP con prefijo sp_
â”‚   â”œâ”€â”€ bronze_to_silver/           # Transformaciones
â”‚   â”œâ”€â”€ silver_to_gold/             # MÃ©tricas y KPIs
â”‚   â”œâ”€â”€ schemas/                    # DDL tablas
â”‚   â””â”€â”€ documentation/              # Estrategias tÃ©cnicas
â”‚
â”œâ”€â”€ ğŸ”§ lakehouse_processing/         # Pipeline DataProc
â”‚   â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â””â”€â”€ README.md                   # Docs DataProc
â”‚
â”œâ”€â”€ ğŸŒ landing/                     # Extractores de datos
â”‚   â”œâ”€â”€ simbad/                     # SIMBAD API harvester
â”‚   â””â”€â”€ macroeconomics/             # Datos macro scraper
â”‚
â”œâ”€â”€ ğŸš€ web_app/                     # Interfaz web (opcional)
â”‚   â”œâ”€â”€ frontend/                   # React + TypeScript
â”‚   â””â”€â”€ backend/                    # FastAPI + Python
â”‚
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md              # DocumentaciÃ³n arquitectural
â””â”€â”€ ğŸ“‹ README.md                    # Este archivo
```

## ğŸš€ **Quick Start**

### **1. Prerrequisitos**
```bash
# Configurar GCP
gcloud config set project proyecto-integrador-dae-2025
gcloud auth application-default login

# Habilitar servicios
gcloud services enable bigquery.googleapis.com \
    dataproc.googleapis.com \
    cloudbuild.googleapis.com \
    cloudscheduler.googleapis.com \
    storage.googleapis.com
```

### **2. Deploy Pipeline**
```bash
# 1. Crear external tables
bq query < bigquery_processing/schemas/bronze_external_tables.sql

# 2. Deploy stored procedures
bq query < bigquery_processing/stored_procedures/sp_*.sql

# 3. Configurar scheduling
gcloud scheduler jobs create http simbad-daily \
  --schedule="0 5 * * *" \
  --uri="https://us-central1-proyecto-integrador-dae-2025.cloudfunctions.net/trigger-simbad"
```

### **3. Ejecutar Pipeline**
```sql
-- Pipeline completo
CALL `proyecto-integrador-dae-2025.gold.sp_full_pipeline_refresh`();

-- Solo incremental
CALL `proyecto-integrador-dae-2025.bronze.sp_process_landing_to_silver_incremental`();
```

## ğŸ“Š **Datos y MÃ©tricas**

### **Fuentes de Datos**
| Dataset | Volumen | Frecuencia | PerÃ­odo |
|---------|---------|------------|---------|
| **SIMBAD Hipotecarios** | 676K+ registros | Mensual | 2012-presente |
| **InflaciÃ³n RD** | Datos diarios | Diario | 2020-presente |
| **Tipo de Cambio** | Compra/Venta | Diario | 2020-presente |
| **Desempleo IMF** | Por paÃ­s | Mensual | 2020-presente |

### **KPIs Principales**
- ğŸ“ˆ **Tasa de Morosidad**: Por entidad/provincia/perÃ­odo
- ğŸ’° **Cobertura de GarantÃ­as**: ValorizaciÃ³n vs deuda
- ğŸ›ï¸ **ConcentraciÃ³n por Entidad**: DistribuciÃ³n de cartera
- ğŸŒ **AnÃ¡lisis GeogrÃ¡fico**: MÃ©tricas por provincia
- ğŸ“Š **CorrelaciÃ³n Macro**: Impacto de inflaciÃ³n/TC en mora

## â° **AutomatizaciÃ³n**

### **Schedule Diario**
```
05:00 AM â†’ Extraer datos SIMBAD + Macro
06:00 AM â†’ Procesamiento incremental Silver
07:00 AM â†’ Actualizar mÃ©tricas Gold
08:00 AM â†’ Generar alertas automÃ¡ticas
```

### **Triggers AutomÃ¡ticos**
- âœ… **Nuevos archivos** en Landing â†’ Trigger procesamiento
- âœ… **Datos Silver listos** â†’ Trigger mÃ©tricas Gold
- âœ… **Alertas detectadas** â†’ Notificaciones automÃ¡ticas

## ğŸ”§ **TecnologÃ­as**

### **Core Stack**
- **â˜ï¸ Google Cloud Platform**: Infraestructura principal
- **ğŸ“Š BigQuery**: Data warehouse y processing engine
- **âš¡ DataProc**: Cluster PySpark para carga histÃ³rica
- **ğŸ—„ï¸ Cloud Storage**: Data lake storage
- **â° Cloud Scheduler**: AutomatizaciÃ³n temporal

### **Processing**
- **ğŸ Python**: Extractores y transformaciones
- **ğŸ”¥ PySpark**: Procesamiento distribuido
- **ğŸ“ SQL**: Transformaciones y mÃ©tricas BigQuery
- **ğŸ”— Stored Procedures**: LÃ³gica de negocio automatizada

### **CI/CD**
- **ğŸ—ï¸ Cloud Build**: Continuous deployment
- **ğŸ“¦ GitHub**: Control de versiones
- **ğŸ³ Docker**: ContainerizaciÃ³n
- **ğŸ“‹ YAML**: ConfiguraciÃ³n como cÃ³digo

## ğŸ“ˆ **Monitoreo**

### **Health Checks**
```sql
-- Estado del pipeline
SELECT process_name, status, rows_processed, message
FROM `proyecto-integrador-dae-2025.gold.process_log`
WHERE created_at >= CURRENT_DATE()
ORDER BY created_at DESC;
```

### **MÃ©tricas Clave**
- **â±ï¸ Latencia**: Landing â†’ Gold < 2 horas
- **ğŸ“Š Volumen**: 676K+ registros procesados
- **âœ… Calidad**: < 1% registros con errores
- **ğŸ”„ Disponibilidad**: 99.9% uptime

## ğŸ” **Estado Actual**

### âœ… **Componentes Funcionales**
- âœ… **Landing extractors**: SIMBAD + MacroeconomÃ­a
- âœ… **DataProc notebooks**: Carga histÃ³rica Bronze
- âœ… **BigQuery external tables**: Bronze layer activo
- âœ… **Silver tables**: Datos limpios disponibles
- âœ… **Gold metrics**: KPIs agregados funcionando
- âœ… **Stored procedures**: AutomatizaciÃ³n lista
- âœ… **Architecture docs**: DocumentaciÃ³n completa

### ğŸ”„ **En Deploy**
- ğŸ”„ **External table CSV**: Landing â†’ Silver direct
- ğŸ”„ **Cloud Scheduler**: Jobs automatizados
- ğŸ”„ **Incremental loading**: OptimizaciÃ³n final
- ğŸ”„ **Alerting system**: Notificaciones automÃ¡ticas

## ğŸ¤ **ContribuciÃ³n**

### **Para Desarrolladores**
1. **Clone**: `git clone https://github.com/noctics123/dmc_proyecto_integrador.git`
2. **Setup**: Seguir [Quick Start](#-quick-start)
3. **Develop**: Trabajar en rama `desarrollo`
4. **PR**: Merge a `main` para deploy automÃ¡tico

### **Para Analistas**
- **Dashboards**: Acceso directo a Looker Studio
- **Queries**: BigQuery pÃºblico para consultas ad-hoc
- **Alertas**: ConfiguraciÃ³n de notificaciones personalizadas

## ğŸ“š **DocumentaciÃ³n**

- ğŸ—ï¸ **[ARCHITECTURE.md](./ARCHITECTURE.md)**: Arquitectura tÃ©cnica completa
- ğŸ“Š **[bigquery_processing/README.md](./bigquery_processing/README.md)**: Pipeline SQL BigQuery
- ğŸ”§ **[lakehouse_processing/README.md](./lakehouse_processing/README.md)**: Pipeline DataProc
- ğŸ“ˆ **[Incremental Strategy](./bigquery_processing/documentation/incremental_loading_strategy.md)**: Estrategia de carga optimizada

## ğŸ“ **Soporte**

- **Issues**: [GitHub Issues](https://github.com/noctics123/dmc_proyecto_integrador/issues)
- **Documentation**: Ver archivos markdown en cada directorio
- **Monitoring**: Logs centralizados en Cloud Logging

---

**ğŸ¯ Pipeline robusto, escalable y automatizado para anÃ¡lisis integral de riesgo crediticio en RepÃºblica Dominicana.**