# BigQuery Processing Pipeline

Pipeline de transformaci√≥n de datos usando BigQuery para capas Silver y Gold del lakehouse.

## üìä Arquitectura Actual

### **Flujo de Datos**
```
DataProc (Notebooks) ‚Üí Bronze (External Tables) ‚Üí BigQuery Silver ‚Üí BigQuery Gold
```

### **Datasets en BigQuery**
- **bronze**: Tablas externas que apuntan a Parquet en GCS
- **silver_clean**: Datos limpios y normalizados
- **gold**: M√©tricas agregadas y KPIs de negocio

## üìÅ Estructura del Repositorio

```
bigquery_processing/
‚îú‚îÄ‚îÄ üìÅ bronze_to_silver/           # Transformaciones Bronze ‚Üí Silver
‚îÇ   ‚îú‚îÄ‚îÄ simbad_cleaning.sql        # Limpieza de datos SIMBAD
‚îÇ   ‚îî‚îÄ‚îÄ macroeconomics_cleaning.sql # Normalizaci√≥n datos macro
‚îÇ
‚îú‚îÄ‚îÄ üìÅ silver_to_gold/             # Transformaciones Silver ‚Üí Gold
‚îÇ   ‚îú‚îÄ‚îÄ simbad_aggregations.sql    # KPIs y m√©tricas SIMBAD
‚îÇ   ‚îî‚îÄ‚îÄ combined_metrics.sql       # M√©tricas combinadas con macro
‚îÇ
‚îú‚îÄ‚îÄ üìÅ stored_procedures/          # Stored Procedures con prefijo sp_
‚îÇ   ‚îú‚îÄ‚îÄ sp_process_bronze_to_silver.sql
‚îÇ   ‚îú‚îÄ‚îÄ sp_process_silver_to_gold.sql
‚îÇ   ‚îî‚îÄ‚îÄ sp_full_pipeline_refresh.sql
‚îÇ
‚îú‚îÄ‚îÄ üìÅ schemas/                    # Definiciones de esquemas
‚îÇ   ‚îú‚îÄ‚îÄ bronze_external_tables.sql
‚îÇ   ‚îú‚îÄ‚îÄ silver_tables.sql
‚îÇ   ‚îî‚îÄ‚îÄ gold_tables.sql
‚îÇ
‚îî‚îÄ‚îÄ üìÅ documentation/              # Documentaci√≥n t√©cnica
    ‚îú‚îÄ‚îÄ data_lineage.md
    ‚îú‚îÄ‚îÄ incremental_loading.md
    ‚îî‚îÄ‚îÄ scheduling_guide.md
```

## üîÑ Patrones de Carga Identificados

### **Estado Actual - An√°lisis**
- **Silver**: Una sola carga (dt_captura = 2025-08-12) con 110K registros
- **Gold**: Datos desde 2012-07 hasta 2025-06 con 4,965 registros
- **Patr√≥n**: Parece ser carga completa (full load), no incremental

### **Comportamiento por Capa**

#### **Bronze Layer (DataProc)**
- ‚úÖ **Incremental**: Detecta √∫ltimo dt= autom√°ticamente
- ‚úÖ **Eficiente**: Solo procesa nuevos archivos CSV‚ÜíParquet

#### **Silver Layer (BigQuery)**
- ‚ùì **A verificar**: ¬øReprocesa todo bronze o solo nuevos dt_captura?
- üìä **Evidencia**: Solo un dt_captura sugiere carga completa

#### **Gold Layer (BigQuery)**
- ‚ùì **A verificar**: ¬øRecalcula todas las m√©tricas o solo per√≠odos nuevos?
- üìä **Distribuci√≥n**: 32 registros consistentes por mes (agregaci√≥n por provincia)

## ‚ö° Recomendaciones de Optimizaci√≥n

### **1. Implementar Carga Incremental Real**
```sql
-- Ejemplo: Solo procesar nuevos dt_captura
WHERE dt_captura > (SELECT MAX(dt_captura) FROM silver_clean.simbad_hipotecarios)
```

### **2. Particionado Inteligente**
- **Silver**: Particionar por dt_captura (carga)
- **Gold**: Particionar por periodo_date (per√≠odo de datos)

### **3. Stored Procedures Inteligentes**
- `sp_incremental_silver_refresh()` - Solo nuevos datos
- `sp_full_silver_rebuild()` - Reconstrucci√≥n completa
- `sp_gold_update_period(start_date, end_date)` - Actualizaci√≥n selectiva

## üéØ Pr√≥ximos Pasos

1. **Extraer queries actuales** de BigQuery scheduled queries/jobs
2. **Crear stored procedures** con l√≥gica incremental
3. **Implementar checkpoints** para detectar √∫ltimo procesamiento
4. **Configurar scheduling** optimizado en Cloud Scheduler
5. **Documentar lineage** y dependencias entre capas

## üìà M√©tricas Clave

### **Vol√∫menes Actuales**
- **Bronze SIMBAD**: ~676K filas (hist√≥rico completo)
- **Silver SIMBAD**: 110K filas (limpio)
- **Gold SIMBAD**: 4.9K filas (agregado por provincia/per√≠odo)

### **Frecuencias Objetivo**
- **Bronze**: Diario (incremental por DataProc)
- **Silver**: Diario (incremental por BigQuery)
- **Gold**: Diario (solo per√≠odos nuevos/actualizados)